Я разрабатываю ИИ-агента, который будет работать с Trade API биржи FINAM. Проект написан на Spring Boot, Spring AI, java 21, Gradle (Groovy DSL).
Цель ИИ-агента - сформировать submission.csv файл, который будет загружен в проверяющую систему. 

Во вложении текущий исходный код проекта в txt и описание задачи в файле task-description.md.

Как это должно работать. 

- Когда приходит запрос в POST /dialogs/{dialogId}/messages, то это приводит к созданию UserAsyncTask. 
  Если в запросе был передан csv-файл, то в таблице prompts будут созданы записи

- Далее ИИ-агент начинает обрабатывать UserAsyncTask

- Если в таблице prompts есть записи, связанные с ChatMessage, который в свою очередь связан с UserAsyncTask, 
  то ИИ-агент как бы переходит в режим заполнения submission таблицы

- В проекте есть набор классов с tool-ами для LLM, которые будут переданы LLM средствами Spring AI.
  Тулы по сути оборачивают методы Trade API.

Описание режима заполнения submissions таблицы.
(Далее идет всего лишь моя идея как можно реализовать этот режим, ты можешь её изменить или улучшить)

ИИ-агент начинает подготовку ответного ChatMessage, к которому будут прилинкованы записи в таблице submissions.
ИИ-агент перебирает записи в таблице prompts. Для каждой записи формируется запрос в LLM.

Главная и самая важная задача LLM — для каждого questions из таблицы prompts в конечном итоге предоставить один вызов метода к Trade API.
Может быть сделано любое кол-во промежуточных вызовов tool-ов, но в итоге с каждой записью из таблицы prompts нужно сопоставить только один вызов API, 
который дает ответ на запрос пользователя. LLM нужно четко сформулировать задачу, 
что она занимается маппингом вопросов от пользователя в запросы к Trade API, которые нужно делать через tool-ы. 
LLM нужно передавать из таблицы prompts question и его uid. LLM при вызове tool-а должна передавать uid.
В каждом tool-е делает http-запрос с помощью feign-клиента.

Далее нужно как-то реализовать перехват вызова tool-ов с помощью аспекта.
Каким-то образом нужно для запросов feign сделать RequestInterceptor, который получит переданный в tool параметр promptUid.
Перед совершением запроса нужно для этого promptUid в таблицу submissions вставить запись с помощью upsert-метода SubmissionService.upsertByPromtUid().
В этой записи должны быть данные о promptUid, ссылка на запись в таблице Prompt, ссылка на ChatMessage, 
type описывающий метод http и request описывающий path и query параметры url. 
То есть могут быть вызваны разные tool-ы для конкретного promptUid, но в таблице submission останется последний вызванный tool. 

Когда таким образом будут обработаны все нужные записи в таблице prompts, нужно перевести UserAsyncTask в статус DONE.
Будет здорово если получится перебирать записи в таблице prompts в несколько потоков и делать параллельные запросы в LLM.
Это ускорит обработку записей в таблице prompts. Должен быть application проперты, который устанавливает уровень параллелизма для этой задачи.
Если параметр равен 1, то обработка будет в один поток. Если > 1, то между потоками нужно равномерно разделить записи в таблице prompts.
Нужно защититься от гонок данных, когда будут происходить вызовы tool-ов.

Использую лучшие практики, паттерны и подходы реализуй все указанные мною требования. Разработай ИИ-агента и весь сопутствующий необходимый код.
Для запросов в LLM используй бин LlmServiceImpl и его методы. Для LLM передавай доступные tool-ы.
При создании файла исходного кода, указывай полностью весь код java-класса.
Если нужно изменить существующий файл в проекте, указывай полностью новую версию методов и требуемые поля.
Никогда не пиши в коде строки с java импортами, которые предшествуют декларации class-а или интерфейса.
Никогда в исходном коде не пиши рядом с названиями классов полный путь к ним через путь к пакету.

Должен получится лучший ИИ-агент, который будет решать задачу маппинга вопросов пользователя на http-запрос к Trade API.